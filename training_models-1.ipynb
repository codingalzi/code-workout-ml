{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78920a7-7765-4546-9d50-7215cb3ccf5f",
   "metadata": {},
   "source": [
    "(ch:trainingModels)=\n",
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00febf-80a1-40a7-bf2b-c6bad314b719",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**감사의 글**\n",
    "\n",
    "자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a2197-b0d9-4c1d-ba6d-990f6fd8cca2",
   "metadata": {},
   "source": [
    "**소스코드**\n",
    "\n",
    "본문에 소개된 코드는 \n",
    "[(구글코랩) 모델 훈련](https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/notebooks/code_training_models.ipynb)에서 \n",
    "직접 실행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c832e-e348-4d01-b3f5-26408dc437ee",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**주요 내용**\n",
    "\n",
    "* 선형 회귀\n",
    "* 경사하강법\n",
    "* 다항 회귀\n",
    "* 학습 곡선\n",
    "* 모델 규제\n",
    "* 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54483515-b638-47b5-877f-f761ec1fee75",
   "metadata": {},
   "source": [
    "**슬라이드**\n",
    "\n",
    "본문 내용을 요약한\n",
    "[슬라이드 1부](https://github.com/codingalzi/handson-ml3/raw/master/slides/slides-training_models-1.pdf),\n",
    "[슬라이드 2부](https://github.com/codingalzi/handson-ml3/raw/master/slides/slides-training_models-2.pdf)\n",
    "다운로드할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4efbf8-de18-4987-8980-8112dd4084f3",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032b071-009c-4cc0-a610-8e33b49848e6",
   "metadata": {},
   "source": [
    "지금까지 살펴 본 두 개의 선형 회귀 모델을 이용하여 머신러닝 모델의 기능과\n",
    "훈련 과정의 이해에 중요한 기초 개념을 살펴 본다.\n",
    "선형 회귀 모델을 예제로 사용하는 이유는 크게 두 가지다.\n",
    "\n",
    "첫째, 선형 회귀 모델의 훈련 과정이 매우 단순하여 머신러닝의 기초 개념을 설명하는 데에 매우 유용하다.\n",
    "\n",
    "둘째, 딥러닝 심층 신경망 모델 등 대다수의 머신러닝 모델이 훈련 과정에서 선형 회귀 모델의 훈련 방식을 활용하면서 보다 복잡한 문제들을 해결한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12acf14e-b417-4bd7-b512-0841c2506339",
   "metadata": {},
   "source": [
    "### 머신러닝 모델이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185745a8-3ee0-4d2c-9a9d-cadc229c348a",
   "metadata": {},
   "source": [
    "먼저 앞서 살펴 본 두 개의 선형 회귀 모델이 예측값을 계산하는 방식을 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a29a6-d171-4bb1-b135-6722f6f68880",
   "metadata": {},
   "source": [
    "**예제: 1인당 GDP와 삶의 만족도**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599e210-15a0-4815-a994-22a02d7064e3",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "{numref}`%s절 <sec:model_based_learning>`에서 1인당 GDP와 삶의 만족도 사이의 \n",
    "관계를 다음 1차 방정식 함수로 표현할 수 있었다.\n",
    "\n",
    "$$\\text{삶의만족도} = \\theta_0 + (\\text{1인당GDP}) \\cdot \\theta_1$$\n",
    "\n",
    "위 함수는 1인당 GDP가 주어지면 삶의 만족도를 예측한다.\n",
    "이를 보다 수학적으로 표현하면 다음과 같다. \n",
    "\n",
    "$$\\hat y = \\theta_0 + x_1 \\cdot \\theta_1$$\n",
    "\n",
    "위 식에서 $x_1$은 1인당 GDP를 가리키는 특성값이고,\n",
    "$\\hat y$는 예측된 삶의 만족도다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af6c612-6c90-42b2-9d12-b68823849120",
   "metadata": {},
   "source": [
    "**예제: 캘리포니아 주택 가격 예측**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8e7ad-7cfd-4d65-b4b6-f9e1e9fae531",
   "metadata": {},
   "source": [
    "{numref}`%s장 <ch:end2end>`에서 다룬 캘리포니아 주택 가격 예측 선형 회귀 모델은\n",
    "24개의 입력 특성을 다룬다. \n",
    "따라서 아래 모양의 아래 함수를 이용하여 예측값을 계산한다.\n",
    "\n",
    "$$\\hat y = \\theta_0 + x_1 \\cdot \\theta_1 + \\cdots + x_{24} \\cdot \\theta_{24}$$\n",
    "\n",
    "* $\\hat y$: 예측된 주택 중위 가격\n",
    "* $x_i$: 구역의 $i$ 번째 특성값(위도, 경도, 중간소득, 가구당 인원 등)\n",
    "* $\\theta_0$: 편향\n",
    "* $\\theta_i$: $i$ 번째 특성에 대한 가중치. 단, $1 \\le i \\le 24$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439ee5b-dfaa-4b60-866a-09be5bed4674",
   "metadata": {},
   "source": [
    "**선형 회귀 예측값**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed5015-8aa9-4515-b1be-402669887b91",
   "metadata": {},
   "source": [
    "위 두 개의 예제에서 설명한 선형 회귀 모델이 \n",
    "예측값을 생성할 때 사용하는 선형 함수를 일반화하면 다음과 같다.\n",
    "\n",
    "먼저 훈련셋에 포함된 샘플이 $n$ 개의 특성 $x_1$, $x_2$, ..., $x_n$을 갖는다고 가정한다.\n",
    "그러면 선형 회귀 모델은 아래 식을 이용하여 예측값을 계산한다.\n",
    "$\\theta_0$와 1을 곱해주는 이유는 다른 항과의 형식을 맞추기 위함이다.\n",
    "\n",
    "$$\\hat y = 1\\cdot \\theta_0 + x_1 \\cdot \\theta_1 + \\cdots + x_n \\cdot \\theta_{n}$$\n",
    "\n",
    "아래 사진은 위 식을 시각화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291f54c-dd22-4fec-ba96-e508e4419361",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/perceptron02.png\" width=\"250\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d08a03-0dba-4d86-a8aa-340eeb36fa24",
   "metadata": {},
   "source": [
    "**선형 회귀 모델 훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce882e5c-8314-4e2c-8722-17e98372ca44",
   "metadata": {},
   "source": [
    "입력값과 타깃 사이의 숨은 관계를 알아내는 일이 바로 머신러닝 모델을 훈련시키는 주요 목표다.\n",
    "예를 들어 선형 회귀 모델은 입력값과 예측값 사이의 관계를 앞서 설명한 대로\n",
    "입력값의 특성과 $\\theta_i$의 선형 조합으로 추정한다.\n",
    "선형 회귀 모델을 훈련시킬 때 $\\theta_i$를 처음에는 무작위로 선택해서 점차 보다 좋은 값으로 업데이트하면서\n",
    "최적의 $\\theta_i$를 찾아가는데, 이때 일반적으로 경사하강법을 적용한다.\n",
    "\n",
    "모든 머신러닝 모델은 각자 고유의 방식으로 예측값을 계산하며,\n",
    "일반적으로 학습된 파라미터를 이용하여 예측값을 계산한다.\n",
    "파라미터 학습은 일반적으로 경사하강법을 이용하며 \n",
    "선형 회귀 모델의 훈련 방식과 예측값 계산 방식이 기초를 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16bd49-d59c-47bd-a09c-cc616131f3a6",
   "metadata": {},
   "source": [
    "**파라미터, 편향, 가중치**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b6829-5285-42b6-bb25-80ba4c15eec3",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "선형 회귀 모델이 입력값에 대한 예측값을 계산할 때 사용하는 $\\theta_0$, $\\theta_1$, ..., $\\theta_{n}$은\n",
    "모델이 훈련을 통해 학습한 **파라미터**<font size=\"2\">parameter</font>다.\n",
    "파라미터 중에 $\\theta_0$은 **편향**<font size=\"2\">bias</font>, \n",
    "나머지 파라미터는 **가중치**<font size=\"2\">weight</font>라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4b61b-34fc-4b15-96cf-2940544b1802",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 행렬 연산 표기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da245338-5da3-4753-99b9-65d70ddeae29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "지금까지 설명한 선형 회귀 모델의 예측값은 하나의 입력값에 대해서만 계산되는 방식이다.\n",
    "그런데 머신러닝 모델은 임의의 개수의 입력값에 대해 동시에 예측값을 계산할 수 있다.\n",
    "\n",
    "사이킷런의 모든 머신러닝 모델은 입력값으로 2차원 어레이를 요구한다.\n",
    "예를 들어 4개의 특성을 갖는 입력값에 대해 훈련된 모델은 입력값으로 임의의 양의 정수 `m`에 대해\n",
    "`(m, 4)` 모양의 데이터프레임 또는 2차원 어레이를 입력값으로 받아 예측값을 계산한다.\n",
    "\n",
    "예를 들어, 4개의 특성을 사용하는 훈련셋으로 훈련된 `LinearRegression` 모델은 훈련중에 또는 실전에서\n",
    "아래 `(3, 4)` 모양의 2차원 어레이를 입력값으로 받으면 3개의 예측값을 계산한다.\n",
    "\n",
    "```python\n",
    "X = array([[0.89, 0.37, 0.39, 0.97],\n",
    "           [0.95, 0.04, 0.24, 0.02],\n",
    "           [0.57, 2.91, 1.25, 0.39]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ab915-98f4-4841-b443-198a7573970d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`(3, 4)` 모양의 어레이를 일반적인 형태를 다음과 같이 표현할 수 있다.\n",
    "단, $x_j^{(i)}$는 $i$-번째 샘플의 $j$-번째 특성값을 가리킨다.\n",
    "즉, $i$는 1부터 3까지, $j$는 1부터 4까지 움직인다.\n",
    "\n",
    "$$\n",
    "\\begin{matrix} \n",
    "\\text{array}([\\,[x_1^{(1)}, x_2^{(1)}, x_3^{(1)}, x_4^{(1)}], \\\\\n",
    "{}\\quad\\quad\\,\\,\\,\\,\\,\\, [x_1^{(2)}, x_2^{(2)}, x_3^{(2)}, x_4^{(2)}], \\\\\n",
    "{}\\quad\\quad\\quad\\,\\,\\,\\, [x_1^{(3)}, x_2^{(3)}, x_3^{(3)}, x_4^{(3)}]\\,])\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3aaad-b834-4c4d-83d5-df728b3daa9f",
   "metadata": {},
   "source": [
    "그러면 3개의 예측값을 계산하기 위해 선형 회귀 모델은\n",
    "내부에서 아래 형식의 행렬곱셈을 수행한다.\n",
    "첫째 열에 추가된 1은 편향에 곱해지는 값을 맞추기 위함이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8f9ae-48f5-4c62-92d1-b90340ee6c77",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\mathbf y} \n",
    "= \\begin{bmatrix}\n",
    "\\hat y_1 \\\\\n",
    "\\hat y_2 \\\\\n",
    "\\hat y_3 \n",
    "\\end{bmatrix}\n",
    "&= \\begin{bmatrix} \n",
    "1\\,\\, x_1^{(1)}\\,\\, x_2^{(1)}\\,\\, x_3^{(1)}\\,\\, x_4^{(1)} \\\\\n",
    "1\\,\\, x_1^{(2)}\\,\\, x_2^{(2)}\\,\\, x_3^{(2)}\\,\\, x_4^{(2)} \\\\\n",
    "1\\,\\, x_1^{(3)}\\,\\, x_2^{(3)}\\,\\, x_3^{(3)}\\,\\, x_4^{(3)}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1 \\\\\n",
    "\\theta_2 \\\\\n",
    "\\theta_3 \n",
    "\\end{bmatrix} \\\\[1.2ex]\n",
    "&= \\begin{bmatrix} \n",
    "1\\cdot \\theta_0 + x_1^{(1)}\\cdot \\theta_1 + x_2^{(1)}\\cdot \\theta_2 + x_3^{(1)}\\cdot \\theta_3 + x_4^{(1)}\\cdot \\theta_4 \\\\\n",
    "1\\cdot \\theta_0 + x_1^{(2)}\\cdot \\theta_1 + x_2^{(2)}\\cdot \\theta_2 + x_3^{(2)}\\cdot \\theta_3 + x_4^{(2)}\\cdot \\theta_4 \\\\\n",
    "1\\cdot \\theta_0 + x_1^{(3)}\\cdot \\theta_1 + x_2^{(3)}\\cdot \\theta_2 + x_3^{(3)}\\cdot \\theta_3 + x_4^{(3)}\\cdot \\theta_4\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29874696-32c1-45ed-80f6-826cd9ae4875",
   "metadata": {},
   "source": [
    "따라서 앞서 언급된 `(3, 4)` 모양의 2차원 어레이 `X`에 대한 예측값은 다음과 같이 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c51d08-b58f-4056-b008-72fa91251f6a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\mathbf y} \n",
    "= \\begin{bmatrix}\n",
    "\\hat y_1 \\\\\n",
    "\\hat y_2 \\\\\n",
    "\\hat y_3 \n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix} \n",
    "1\\cdot \\theta_0 + 0.89\\cdot \\theta_1 + 0.37\\cdot \\theta_2 + 0.39\\cdot \\theta_3 + 0.97\\cdot \\theta_4 \\\\\n",
    "1\\cdot \\theta_0 + 0.95\\cdot \\theta_1 + 0.04\\cdot \\theta_2 + 0.24\\cdot \\theta_3 + 0.02\\cdot \\theta_4 \\\\\n",
    "1\\cdot \\theta_0 + 0.57\\cdot \\theta_1 + 2.91\\cdot \\theta_2 + 1.25\\cdot \\theta_3 + 0.39\\cdot \\theta_4\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1fab4-6aff-4eb6-8e1b-295a1a4000c2",
   "metadata": {},
   "source": [
    "### 머신러닝 모델 훈련의 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dac3a-8056-41fd-ab99-3dc68ff0d0e9",
   "metadata": {},
   "source": [
    "머신러닝 모델의 훈련은 타깃에 최대한 가까운 예측값 계산을 목표로 한다.\n",
    "한마디로 말해 모델의 예측 성능을 최대한 높혀야 한다.\n",
    "모델 훈련중에는 모델의 성능을 일반적으로 모델의 비용 함수를 이용하여 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc572bf-d9ca-43a1-ac16-40243cd38eb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**비용 함수**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e738a-c412-4fc3-80b4-5347ad294413",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "비용 함수<font size='2'>cost function</font>는 모델의 성능이 얼마나 나쁜가를 계산한다.\n",
    "비용 함수가 계산하는 값이 작을 수록 해당 모델의 성능이 좋은 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29fa29d-9777-45a5-9860-03821992ec9e",
   "metadata": {},
   "source": [
    ":::{admonition} 비용 함수와 손실 함수\n",
    ":class: note\n",
    "\n",
    "비용 함수는 손실 함수<font size='2'>loss function</font>,\n",
    "비용 함수에 의해 계산된 값은 손실값<font size='2'>loss</font>이라 부르기도 한다.\n",
    "사람에 따라 두 함수의 기능을 구분하기도 하지만 여기서는 동일한 함수로 취급한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c4189-bfb8-45d0-8732-3c74c8a63bc7",
   "metadata": {},
   "source": [
    "**MSE: 회귀 모델의 비용 함수**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3d6c9-1fe5-4c59-832c-8037a9ca2cd0",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "비용 함수는 모델 종류와 목표에 따라 다르게 정의되지만\n",
    "회귀 모델의 경우 일반적으로 **평균 제곱 오차**<font size=\"2\">mean squared error</font>(MSE)를\n",
    "비용 함수로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5259557-672d-4f2d-a3f8-0478f7518425",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\mathrm{MSE}(\\mathbf{\\theta}) = \n",
    "\\frac 1 m \\sum_{i=1}^{m} \\big(\\mathbf{x}^{(i)}\\, \\mathbf{\\theta} - y^{(i)}\\big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c8d8a-0375-47bf-b671-66fce12d08f4",
   "metadata": {},
   "source": [
    "위 수식에서 포함된 기호들의 의미는 다음과 같다.\n",
    "\n",
    "| 기호 | 의미 |\n",
    "| :---: | :--- |\n",
    "| $\\mathbf{x}^{(i)}$ | $i$ 번째 샘플. 단 0번 인덱스에 1이 추가됨. |\n",
    "| $y^{(i)}$ | $i$ 번째 샘플에 대한 타깃 |\n",
    "| $\\mathbf{\\theta}$ | 파라미터(편향과 가중치)로 구성된 1차원 어레이 |\n",
    "| $m$ | 훈련셋 크기 또는 배치 크기 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb1cff-b453-40c3-acf6-fcce387f9b92",
   "metadata": {},
   "source": [
    "또한 $\\mathbf{x}^{(i)}\\, \\mathbf{\\theta}$ 는 $i$-번째 샘플에 대한 예측값 $\\hat y^{(i)}$를 가리킨다.\n",
    "이때 $i$는 $1$부터 $m$까지 움직인다.\n",
    "\n",
    "$$\n",
    "\\hat y^{(i)} = \\mathbf{x}^{(i)}\\, \\mathbf{\\theta} = 1\\cdot \\theta_0 + x^{(i)}_1 \\cdot \\theta_1 + \\cdots + x^{(i)}_n \\cdot \\theta_{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62fed9a-d297-498a-a229-a206bd072d73",
   "metadata": {},
   "source": [
    "**모델 훈련의 최종 목표**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8846a-37e5-4030-8d9b-71baf4888b7f",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "훈련셋이 주어졌을 때 $\\mathrm{MSE}(\\mathbf{\\theta})$가 최소가 되도록 하는 \n",
    "$\\mathbf{\\theta}$를 찾아야 한다.\n",
    "선형 회귀의 경우 모델에 따라 다음 두 가지 방식 중 하나를 이용하여 해결한다.\n",
    "\n",
    "* 방식 1: 정규방정식 또는 특이값 분해(SVD)\n",
    "\n",
    "* 방식 2: 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c7d4dc-8391-4186-80cb-75404d5f1aa2",
   "metadata": {},
   "source": [
    "정규 방정식은 `LinearRegression` 등 선형 회귀를 활용하는 극히 일부 모델에서, 그것도 훈련셋의 크기와\n",
    "입력 특성수 모두 작을 때만 활용된다. \n",
    "반면에 경사하강법은 딥러닝 모델에서도 기본으로 활용되는 훈련 기법이다.\n",
    "이런 의미에서 정규 방정식은 여기서는 다루지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ae201-a9c1-41b1-a9a2-d30eaf92b4fd",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(sec:gradient-descent)=\n",
    "## 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d3ac3-ce54-45a0-af1e-cae388e24492",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "경사하강법을 이해하려면 먼저 아래 개념들을 충분히 숙지해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a922148-23ae-4be8-8022-fefd6710e2a0",
   "metadata": {},
   "source": [
    "**하이퍼파라미터<font size=\"2\">hyperparameter</font>**\n",
    "\n",
    "훈련시킬 모델을 지정할 때 사용되는 설정 옵션, \n",
    "즉 해당 클래스의 객체를 생성할 때 클래스의 생성자 함수에 전달되는 인자들을 가리킨다.\n",
    "대표적으로 학습률, 에포크, 허용 오차, 배치 크기 등이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590c6ff-802d-4fcd-a2d5-6b632df9b66d",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**파라미터**<font size=\"2\">parameter</font>\n",
    "\n",
    "선형 회귀 모델에 사용되는 편향과 가중치 파라미터처럼 모델 훈련중에 학습되는 값들을 가리킨다.\n",
    "모델 훈련을 통해 학습된 파라미터는 훈련된 모델 객체의 속성으로 저장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135bf03-dfdb-4f12-ab0b-ba677b405cb2",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**스텝**<font size='2'>step</font>\n",
    "\n",
    "모델이 파라미터를 한 번 업데이트 하는 과정을 가리킨다.\n",
    "배치 크기 $m$ 만큼의 샘플에 대해 예측값을 계산한 후에 \n",
    "비용 함수를 이용하여 성능을 평가한 후에 \n",
    "비용 함수의 값, 즉 손실값을 줄이는 방향으로 파라미터를 한 번 업데이트 하는 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2100fada-a7d1-4cdb-9042-7802e43065a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/step.png\" width=\"300\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6acd5-0a68-4f20-b0fe-579555feca21",
   "metadata": {},
   "source": [
    "`SGDRegressor` 모델은 크기가 1인 배치로 훈련하기에 하나의 스텝에 하나의 데이터 샘플만 활용한다.\n",
    "즉, 아래 과정으로 구성된 스텝을 훈련셋에 포함된 각각의 샘플에 대해 반복해서 진행한다.\n",
    "\n",
    "- 하나의 데이터 샘플에 대한 예측값 계산\n",
    "- MSE 계산\n",
    "- MSE의 그레이디언트 계산\n",
    "- $\\theta$ 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc010e-2532-47f1-839d-ccae1ace5886",
   "metadata": {},
   "source": [
    "**배치 크기**\n",
    "\n",
    "파라미터를 한 번 업데이트 하기 위해 사용된 훈련 데이터 샘플의 개수를 가리킨다.\n",
    "즉, 한 번의 스텝에서 사용되는 훈련 샘플의 개수다.\n",
    "\n",
    "- 사이킷런 모델: 배치 크기 선택 옵션을 지원하지 않음. 경사하강법을 적용하는 모든 모델의 배치 크기는 1로 지정됨.\n",
    "    - `LinearRegression`: 경사하강법 사용하지 않음.\n",
    "    - `SGDRegressor`: $m = 1$\n",
    "    - `LogisticRegressor`: $m = 1$\n",
    "    \n",
    "- 딥러닝 심층 신경망 모델: 배치 크기 선택 옵션을 제공함. 일반적으로 8, 16, 32, 64, 128, 256 중에 하나 선택.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9593b-c4cf-4513-9b7a-1c5d7c95cf7b",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**비용 함수**\n",
    "\n",
    "평균 제곱 오차(MSE)처럼 모델의 성능이 얼마나 나쁜가를 계산하는 함수다.\n",
    "훈련 스텝에서 비용 함수의 값, 즉 손실값은 배치 단위로 계산된다.\n",
    "\n",
    "회귀 모델의 배치 단위로 계산되는 손실값은 평균 제곱 오차(MSE)로 계산된다.\n",
    "예를 들어\n",
    "`SGDRegressor` 모델은 크기가 1인 배치로 훈련하기에\n",
    "매 스텝에서 아래 MSE 계산을 임의로 선택된 샘플 $\\mathbf{x}^{(i)}$ 대해 실행한다.\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}(\\mathbf{\\theta}) = \n",
    "\\big(\\mathbf{x}^{(i)}\\, \\mathbf{\\theta} - y^{(i)}\\big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c3593-5920-4bd7-8f2d-b7ed278495ff",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**비용 함수의 그레이디언트 벡터**<font size='2'>gradient vector</font>\n",
    "\n",
    "비용 함수 $\\mathrm{MSE}(\\mathbf{\\theta})$의 $\\mathbf{\\theta}$에 대한 미분값을 그레이디언트 벡터라 부르며\n",
    "$\\nabla_\\mathbf{\\theta} \\textrm{MSE}(\\mathbf{\\theta})$로 표기한다.\n",
    "그레이디언트 벡터는 파라미터 $\\mathbf{\\theta}$의 크기를 어떻게 업데이트 해야 하는가에 대한 정보를 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d2a20-9e87-4bb9-9de3-582465784a4c",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**학습률($\\eta$)**\n",
    "\n",
    "훈련 스텝마다 파라미터 $\\mathbf{\\theta}$를 얼만큼씩 조정할 것인지를 정하는 비율이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01fe13-2a8e-4acd-b927-0ea22f717c3d",
   "metadata": {},
   "source": [
    "**에포크**<font size=\"2\">epoch</font>\n",
    "\n",
    "훈련셋에 포함된 모든 데이터를 대상으로 예측값을 한 번 계산하는 과정이다.\n",
    "이 과정동안 실행된 스텝 회수만큼 파라미터의 업데이트가 이루어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42232f5-ee97-427a-bf1a-bb29a5cf95ba",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**스텝 횟수**\n",
    "\n",
    "에포크 동안 실행된 스텝의 횟수, 즉 파라미터를 조정한 횟수다.\n",
    "다음이 성립한다.\n",
    "\n",
    "    스텝 횟수 = (훈련셋 크기) / (배치 크기)\n",
    "\n",
    "예를 들어, 훈련셋 크기가 1,000이고 배치 크기가 10이면 에포크마다 100번의 스텝이 실행된다.\n",
    "반면에 `SGDRegressor` 모델은 크기가 1인 배치로 훈련하기에 한 번의 에포크동안 훈련셋 크기만큼의 스텝이 진행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518ef93-1771-4751-9392-bfd091c7493c",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**최적 학습 모델**\n",
    "\n",
    "비용 함수의 값, 즉 손실값을 최소화하는 파라미터를 학습한(찾아낸) 모델이며,\n",
    "최종적으로 훈련을 통해 얻고자 하는 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b29b6-9087-49af-afa0-b767fb62483e",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**전역/지역 최소값**\n",
    "\n",
    "비용 함수의 전역/지역 최소값이다. \n",
    "예를 들어 선형 회귀 모델의 경우엔 평균 제곱 오차(MSE) 함수가 갖는 전역/지역 최소값을 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7816a5-84b2-47b6-909b-108ad7c9b685",
   "metadata": {},
   "source": [
    "**허용 오차**<font size=\"2\">tolerance</font>\n",
    "\n",
    "보통 5 에포크 정도 반복 훈련이 지나도록 비용 함수의 그레이디언트 벡터의 크기가 \n",
    "허용 오차보다 작아지면 훈련을 종료한다.\n",
    "이유는 그레이디언트 벡터의 크기가 매우 작으면\n",
    "비용 함수의 $\\theta$에 대한 그래프가 매우 완만해졌음을,\n",
    "따라서 비용 함수의 값, 즉 손실값이 거의 변하지 않음을 의미하기 때문이다.\n",
    "결론적으로 비용 함수의 전역 또는 지역 최소값을 계산하는 파라미터 $\\theta$가\n",
    "거의 학습되었음을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f084bdc-6122-4c48-aadc-d36d8911022c",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델 훈련과 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888e56a-52ba-4ac4-b710-0f34e7adb20e",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "MSE를 비용 함수로 사용하는 선형 회귀 모델의 파라미터를 조정하는 \n",
    "과정을 이용하여 경사하강법의 기본 아이디어를 설명한다.\n",
    "\n",
    "선형 회귀 모델 훈련에 사용되는 경사하강법은 아래 과정으로 구성된다.\n",
    "\n",
    "1. $\\mathbf{\\theta}$를 임의의 값으로 지정한 후 훈련을 시작한다.\n",
    "\n",
    "1. 지정된 에포크만큼 또는 비용 함수의 그레이디언트 벡터\n",
    "    $\\nabla_\\mathbf{\\theta} \\textrm{MSE}(\\mathbf{\\theta})$가 허용 오차보다 작아질 때까지\n",
    "    아래 과정으로 구성된 훈련 스텝을 반복한다.\n",
    "\n",
    "    * 배치 크기 $m$ 만큼의 훈련 샘플을 이용해서 예측값 생성 후 $\\mathrm{MSE}(\\mathbf{\\theta})$ 계산.\n",
    "    * $\\mathbf{\\theta}$를 아래 점화식을 이용하여 업데이트\n",
    "\n",
    "$$\n",
    "\\theta^{(\\text{new})} = \\theta^{(\\text{old})}\\, -\\, \\eta\\cdot \\nabla_\\theta \\textrm{MSE}(\\theta^{(\\text{old})})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b4c8e-fc4e-476f-b655-2318cd02a147",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ":::{admonition} 그레이디언트 벡터의 방향과 크기\n",
    ":class: note\n",
    "\n",
    "그레이디언트 벡터 $\\nabla_\\mathbf{\\theta} \\textrm{MSE}(\\mathbf{\\theta})$가 가리키는 방향의\n",
    "**반대 방향**으로 움직이면 빠르게 $\\textrm{MSE}(\\mathbf{\\theta})$가 \n",
    "전역 최소값을 갖는 $\\mathbf{\\theta}$ 접근한다.\n",
    "\n",
    "아래 그림은 $\\mathbf{\\theta}$에 대한 2차 다항식 함수로 계산되는 비용 함수의 그래프상의 \n",
    "한 점에서의 기울기가 양수인 경우 음수쪽으로 움직여야 전역 최소값으로 수렴하는 것을 보여준다. \n",
    "\n",
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/gradient01b.png\" width=\"350\"/></div></p>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.analyticsvidhya.com/blog/2020/10/how-does-the-gradient-descent-algorithm-work-in-machine-learning/\">Analytics Vidhya</a>&gt;</div></p>\n",
    "\n",
    "아래 두 그림은 산에서 가장 경사가 급한 길을 따를 때 가장 빠르게 하산한다는 원리를 보여준다.\n",
    "이유는 해당 지점에서 그레이디언트 벡터를 계산하면 정상으로 가는 가장 빠른 길을 안내할 것이기에\n",
    "그 반대방향으로 움직여야 하기 때문이다.\n",
    "그림에서 보여지는 여러 경로는 경사하강법을 담당하는 여러 알고리즘에 따라 선택된다.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"padding:1px\">\n",
    "            <figure>\n",
    "                <img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/contours_evaluation_optimizers.gif\" style=\"width:90%\" title=\"SGD without momentum\">\n",
    "                <figcaption>SGD optimization on loss surface contours</figcaption>\n",
    "            </figure>\n",
    "        </td>\n",
    "        <td style=\"padding:1px\">\n",
    "            <figure>\n",
    "                <img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/saddle_point_evaluation_optimizers.gif\" style=\"width:90%\" title=\"SGD without momentum\">\n",
    "                <figcaption>SGD optimization on saddle point</figcaption>\n",
    "            </figure>\n",
    "        </td>        \n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.ruder.io/optimizing-gradient-descent/\">An overview of gradient descent optimization algorithms</a>&gt;</div></p>\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf170792-1202-4a02-8d9f-85241d05b958",
   "metadata": {},
   "source": [
    "### 학습률의 중요성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c328ce-1d92-4bb7-a6b2-29b8931074f4",
   "metadata": {},
   "source": [
    "선형 회귀 모델은 적절할 학습률로 경사하강법으로 적용하여 훈련될 경우 \n",
    "빠른 시간에 비용 함수가 전역 최소값을 갖도록 하는 $\\hat{\\theta}$ 에 수렴한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6396e-05a8-43bc-96d8-0a66e423ad1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-01.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e341e36a-0a5e-44fa-b709-db572ea99fae",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "반면에 학습률이 너무 작거나 너무 크면 비용 함수가 전역 최소값을 갖도록 하는 파라미터에\n",
    "너무 느리게 수렴하거나 아예 수렴하지 않을 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b126a2-2455-49ad-92db-ef00d6afeae4",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 학습률이 너무 작은 경우: 비용 함수가 전역 최소값을 갖도록 하는 $\\hat{\\theta}$ 에 너무 느리게 수렴."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5dc20-9f53-41c4-86b0-2e7d5fa9f65c",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-02.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095b681-10b9-43c3-9a01-9b3c5f435b43",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 학습률이 너무 큰 경우: 비용 함수가 전역 최소값을 갖도록 하는 $\\hat{\\theta}$ 에 수렴하지 않고 발산함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304ba738-16a8-416d-8b38-ce96a1dd30e6",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-03.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1920f9-3ead-4e83-9b63-26ef8ad63da4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "아래 세 그림은 학습률에 따라 선형 회귀 모델이 최적의 모델로 수렴하는지 여부와 수렴 속도가 달라지는 것을 잘 보여준다.\n",
    "\n",
    "- $\\eta = 0.02$: 학습률이 너무 작은 경우\n",
    "- $\\eta = 0.1$: 학습률이 적절한 경우\n",
    "- $\\eta = 0.5$: 학습률이 너무 큰 경우\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04b.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc522b8c-98e1-4217-913f-c00f0a8c2dfb",
   "metadata": {},
   "source": [
    "**비선형 모델 훈련의 어려움**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a481f-c411-4c98-9884-804066bbccf6",
   "metadata": {},
   "source": [
    "선형 회귀 모델은 학습률을 적절하게 잡으면 언제나 최적의 모델로 수렴한다.\n",
    "아래 그림은 비선형 모델의 경우엔 하지만 학습률과 상관 없이 파라미터를 초기화하는 방식에 따라 \n",
    "지역 최소값에 수렴하거나 수렴하지 못하고 정체할 수도 있음을 잘 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38284fc3-6674-4e84-b32e-9cb0b3bc71b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04.png\" width=\"500\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657482f-9de7-4880-a8d9-f2f507f5b34c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**특성 스케일링의 중요성**\n",
    "\n",
    "특성들의 스켈일을 통일시키면 보다 빠른 학습이 이루어지는 이유를 \n",
    "아래 그림이 설명한다.\n",
    "\n",
    "* 왼편 그림: 두 특성의 스케일이 동일하게 조정된 경우엔 비용 함수의 최소값으로 최단거리로 수렴한다.\n",
    "     비용 등고선이 원 모양으로 그려지는 경우를 생각하면 된다.\n",
    "* 오른편 그림: 두 특성의 스케일이 다른 경우 비용 함수의 최소값으로 보다 먼 거리를 지나간다.\n",
    "    이런 경우엔 비용 등고선이 타원 모양 또는 찌그러진 모양으로 그려지기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a46be6d-c6ea-4185-8b15-fa4f237194f9",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04a.png\" width=\"500\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fde5db-2d37-4239-9e12-c51098bc37de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 경사하강법 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d81a5d-a8af-4cf8-8530-5e71d81664d1",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "모델 훈련에 사용되는 경사하강법은\n",
    "훈련 대상 모델을 지정할 때 사용하는 하이퍼파라미터 중의 하나인 배치 크기에 따라 세 종류로 나뉜다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f4f3fa-9760-482a-8398-e07de2bdea6a",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**배치 경사하강법**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a715f8f9-c6c0-4bc5-9f4a-4cc00bba6ab2",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "에포크마다 한 번 그레이디언트를 계산하여 파라미터를 조정(업데이트)한다.\n",
    "즉, 배치 크기($m$)가 전체 훈련셋의 크기와 같다. 즉, 스텝의 크기가 1이다.\n",
    "\n",
    "파라미터 업데이트를 에포크에 한 번만 수행 하기에 모델을 지정할 때 에포크를 크게 잡아야 한다.\n",
    "그렇지 않으면 훈련이 제대로 진행하지 않는다.\n",
    "그런데 훈련셋이 크면 그레이디언트를 계산하는 데에 많은 시간과 메모리가 필요해지는 문제가 발생할 수 있다.\n",
    "이와 같은 이유로 인해 사이킷런을 포함하여 일반적으로 배치 경사하강법을 지원하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d040bf-d93e-466f-a252-a061beef3c46",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**확률적 경사하강법(SGD)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23daca67-3368-425f-84a7-318615b076b4",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "배치 크기($m$)가 1인 경상하강법을 가리킨다.\n",
    "즉, 하나의 훈련 셈플에 대한 예측값을 계산한 다음에 바로\n",
    "비용 함수의 그레이디언트를 계산하여 파라미터를 조정한다.\n",
    "\n",
    "스텝에서 사용되는 샘플은 무작위로 선택된다.\n",
    "따라서 경우에 따라 하나의 에포크에서 여러 번 선택되거나 전혀 선택되지 않는 샘플이\n",
    "존재할 수도 있지만, 이는 별로 문제되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1253e-b52c-4271-9ed8-83b1085790ef",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "확률적 경사하강법의 장점은 계산량이 매우 적다는 점이다. \n",
    "따라서 아주 큰 훈련셋을 이용하여 훈련할 수 있다.\n",
    "특히 훈련셋이 너무 커서 조금씩 메모리로 불러와서 훈련을 진행하는 \n",
    "외부 메모리 학습<font size='2'>out-of-core learning</font>에 활용될 수 있다.\n",
    "\n",
    "또한 파라미터 조정이 불안정하게 이뤄질 수 있기 때문에 지역 최소값에 상대적으로 덜 민감하다.\n",
    "반면에 동일한 이유로 경우에 따라 전역 최소값에 수렴하지 못하고 주변을 맴돌 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ea909-cadc-430d-b79d-1000ea83d1f6",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<b><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04c.png\" width=\"300\"/></div></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb95ec-3fea-47ad-9204-f7e22111d210",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "요동치는 파라미터를 제어하기 위해 학습률을 학습 과정 동안 천천히 줄어들도록 하는\n",
    "학습 스케줄<font size=\"2\">learning schedule</font>을 사용한다.\n",
    "학습 스케줄은 일반적으로 훈련 에포크가 진행될 수록 학습률이 조금씩 작아지도록 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c2e6d-f0a1-42fa-8a59-03b3fad072f3",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ":::{prf:example} 사이킷런의 `SGDRegressor` 모델 선언\n",
    ":label: exp-sgdregressor\n",
    "\n",
    "확률적 경사하강법을 사용하는 선형 회귀 모델이다.\n",
    "아래 코드는 에포크 크기, 허용 호차, 학습 스케줄, 규제 적용 여부를 지정하는 하이퍼파라미터를 함께\n",
    "사용하는 것을 보여준다.\n",
    "\n",
    "```python\n",
    "SGDRegressor(penalty=l2, \n",
    "             max_iter=1000, \n",
    "             tol=1e-3, \n",
    "             eta0=0.01,\n",
    "             early_stoppingbool=False,\n",
    "             n_iter_no_change=5, \n",
    "             random_state=42)\n",
    "```\n",
    "\n",
    "* `penalty=l2`: 규제 종류. `None`은 규제 미사용 없음 (추후 설명)\n",
    "* `max_iter=1000`: 최대 에포크 수\n",
    "* `tol=1e-3`: 허용 오차. 손실값이 `n_iter_no_change` 만큼의 에포크 동안 허용 오차보다 작게 변할 때 훈련 중단\n",
    "    - `early_stoppingbool`이 `False`이면 훈련셋에 대한 손실값을, `True`이면 자동으로 분리된 검증셋의 손실값이 사용됨.\n",
    "* `early_stoppingbool=False`: 조기 종료 여부 지정. 기본값은 `False`. (추후 설명)\n",
    "* `eta0=0.01`: 초기 학습률. 학습 스케줄에 활용됨\n",
    "* `n_iter_no_change=5`: 지정된 에포크 동안 손실값이 허용 오차보다 작게 변할 때 훈련 중단\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed3d7f-19b2-4ccc-93c4-c34fe445e3c5",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**미니 배치 경사하강법**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74307302-9d96-4aed-99a9-c6cec22fbe0e",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "배치 크기($m$)를 2 이상으로 잡는 경사하강법이다. \n",
    "보통 2에서 수백 사이로 정한다.\n",
    "배치 크기를 적절히 크게 잡으면 확률적 경사하강법(SGD) 보다 파라미터의 움직임이 덜 불규칙적이 되며,\n",
    "배치 경사하강법보다 훨씬 빠르게 최적 학습 모델에 수렴한다.\n",
    "다만 SGD에 비해 지역 최소값에 수렴할 위험도가 보다 커질 수 있다.\n",
    "하지만 대부분의 딥러닝 심층 신경망 모델에서 지원된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977bf93e-bb7d-435d-9b26-59f681448b69",
   "metadata": {},
   "source": [
    "**세 가지 경사하강법 비교**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b13dfb-01dd-4f64-82e4-086deb3ce3dc",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "아래 그림은 앞서 배치/확률적/미니 배치 경사하강법을 진행할 때 학습되는 파라미터들의 변화 과정을 보여준다.\n",
    "\n",
    "- 배치 경사하강법 파라미터 변화: 진동없이 최적 파라미터에 수렴. 하지만 훈련 시간이 가장 길고, 큰 훈련셋에서는 적용할 수 없음.\n",
    "- 확률적 경가하강법 파라미터 변화: 진동 심함. 최적 파라미터 근처에서 계속 진동하고 수렴하지 못함. 하지만 학습 시간이 매우 짧아서 대용량 훈련셋에 대해 잘 작동함.\n",
    "- 미니 배치 경사하강법 파라미터 변화: 진동이 상대적으로 약하며 나름 최적 파라미터에 잘 접근함. 학습 스케줄을 이용하여 훈련이 진행될 수록 학습률을 줄이면 최적 파라미터에 가깝게 근접함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad2796-c6b9-4166-90cb-e68c1f93b213",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-05.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182618e1-5d76-4eb9-8b3b-730a8b2e9df4",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(sec:poly_reg)=\n",
    "## 비선형 데이터 학습: 다항 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33c645-c695-4101-be9e-6c70bb32d08f",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "비선형 데이터를 선형 회귀를 이용하여 학습하는 기법을\n",
    "**다항 회귀**<font size=\"2\">polynomial regression</font>라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c09d13-0983-4749-bf79-02cbe9787873",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**예제: 2차 함수 모델를 따르는 데이터셋에 선형 회귀 모델 적용**\n",
    "\n",
    "아래 그림은 2차 함수의 그래프 형식으로 분포된 데이터셋을 선형 회귀 모델로 학습시킨 결과를 보여준다.\n",
    "\n",
    "$$\\hat y = \\theta_0 + \\theta_1\\, x_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d889795-dac6-4e58-8503-f0ed12d91382",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-06.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d500918-d14f-427c-bfa2-4f0bf05e82f4",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**예제: 2차 함수 모델를 따르는 데이터셋에 2차 다항식 모델 적용**\n",
    "\n",
    "반면에 아래 그림은 $x_1^2$ 에 해당하는 특성을 새로이 추가한 후에\n",
    "선형 회귀 모델을 학습시킨 결과를 보여준다.\n",
    "\n",
    "$$\\hat y = \\theta_0 + \\theta_1\\, x_1 + \\theta_2\\, x_{1}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc09f8-9dc8-4d0d-adea-96047b3ce6b2",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-07.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff6bb3-cd7a-4e47-8148-c3bf9e2867b4",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**사이킷런의 `PolynomialFeatures` 변환기**\n",
    "\n",
    "지정된 차수의 다항식에 포함되어야 하는 특성을 생성하여 추가하는 변환기다.\n",
    "\n",
    "```python\n",
    "PolynomialFeatures(degree=d, include_bias=False)\n",
    "```\n",
    "`degree=d`는 몇 차 다항식을 활용할지 지정하는 하이퍼파라미터다. \n",
    "`include_bias=False`는 편향에 활용되는 1을 특성으로 추가하지 않는다는 의미이다.\n",
    "원래는 `include_bias=True`가 기본값이기에 모든 샘플에 1을 0번 특성으로 추가해야 하지만\n",
    "여기서는 `LinearRegression` 모델에 의해 편향이 별도로 다뤄지기 때문에 굳이 먼저 추가하지\n",
    "않아도 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd340d-55d8-4433-8869-9c55decc4036",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ":::{prf:example} 2차 다항 회귀\n",
    ":label: exp:2nd_poly_reg\n",
    "\n",
    "기존에 $x_1, x_2$ 두 개의 특성을 갖는 데이터셋에 대해\n",
    "2차 다항식 모델을 훈련시키고자 하면 $d=2$으로 설정한다.\n",
    "그러면 $x_1, x_2$ 을 이용한 2차 다항식에 포함될 항목을 새로운 특성으로 추가해야 한다.\n",
    "즉, $(x_1+x_2)^2$의 항목에 해당하는 다음 3 개의 특성을 추가해야 함을 의미한다.\n",
    "\n",
    "$$x_1^2,\\,\\, x_2^2,\\,\\, x_1 x_2$$\n",
    "\n",
    "위 특성들에 선형 회귀 모델을 훈련시키면 예측값은 아래와 같이 계산된다.\n",
    "\n",
    "$$\n",
    "\\hat y = \n",
    "\\theta_0 + \\theta_1\\, x_1 + \\theta_2\\, x_2\n",
    "+ \\theta_3\\, x_{1} x_2\n",
    "+ \\theta_4\\, x_{1}^2 + \\theta_5\\, x_{2}^2\n",
    "$$\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692d3a8-664a-49ed-8a12-2d8c0c35d4d9",
   "metadata": {},
   "source": [
    "**다항 회귀의 단점**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d790d06-cc7c-469a-9b7d-1e64ec45e3e6",
   "metadata": {},
   "source": [
    "몇차 다항 회귀를 사용해야 할지 일반적으로 알 수 없다. \n",
    "또한 심층 신경망처럼 비선형 데이터를 분석하는 보다 좋은 모델이 개발되어 굳이 다항 회귀를 사용할 필요가 없어졌다.\n",
    "여기서는 비선형 데이터 분석을 선형 회귀 모델로 제대로 예측할 수 없음을 보여주기 위해 언급되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed38b7-43b8-4af8-aa78-86555f02d886",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 학습 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21825a8-da9d-4815-a95c-97699ad7ecc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "사용되는 모델에 따라 훈련된 모델의 성능이 많이 다를 수 있다.\n",
    "아래 그림은 기본 선형 모델은 성능이 너무 좋지 않은 반면에\n",
    "300차 다항 회귀 모델은 너무 과하게 훈련 데이터에 민감하게 반응하는 것을 보여준다.\n",
    "반면에 2차 다항 회귀 모델이 적절(?)하게 예측값을 계산하는 것으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4c25a-3464-411a-afc6-a968816e0243",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-08.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b654fc-2dfc-4ac3-820d-c1948a7fc344",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**모델 성능 평가: 교차 검증 vs. 학습 곡선**\n",
    "\n",
    "일반적으로 어떤 모델이 가장 좋은지 미리 알 수 없다. \n",
    "따라서 보통 다양한 모델을 대상으로 교차 검증을 진행하여 성능을 평가한다.\n",
    "교차 검증 결과에 따른 모델 평가는 다음 두 종류로 나뉜다.\n",
    "\n",
    "* 과소적합: 훈련 점수와 교차 검증 점수 모두 낮은 경우\n",
    "* 과대적합: 훈련 점수는 높지만 교차 검증 점수가 상대적으로 많이 낮은 경우\n",
    "\n",
    "다른 검증 방법은 **학습 곡선**<font size='2'>learning curve</font>을 잘 살펴보는 것이다.\n",
    "학습 곡선은 훈련셋과 검증 세트에 대한 모델 성능을 비교하는 그래프이며,\n",
    "학습 곡선의 모양에 따라 과소 적합 또는 과대 적합 여부를 판정할 수 있다.\n",
    "\n",
    "사이킷런의 `learning_curve()` 함수를 이용하여 학습 곡선을 그릴 수 있다.\n",
    "\n",
    "* x 축: 훈련셋 크기. 전체 훈련셋의 1%에서 출발하여 훈련셋 전체를 대상으로 할 때까지 \n",
    "    훈련셋의 크기를 키워가며 교차 검증 진행.\n",
    "* y 축: 교차 검증을 통해 확인된 훈련셋 및 검증셋 대상 RMSE(평균 제곱근 오차)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18ebab-1f0c-463a-9d7e-09a2672eaa94",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**과소 적합 모델의 학습 곡선 특징**\n",
    "\n",
    "아래 그래프는 2차 다항 함수의 분포를 따르는 데이터셋에 `LinearRegression` 모델을 적용한 학습 곡선을 보여준다.\n",
    "\n",
    "* 훈련셋(빨강)에 대한 성능: 훈련셋이 커지면서 RMSE 증가하지만 \n",
    "    훈련셋이 어느 정도 커지면 거의 불변.\n",
    "\n",
    "* 검증셋(파랑)에 대한 성능: 검증 세트에 대한 성능이 훈련셋에 대한 성능과 거의 비슷해짐."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda4c09-22a4-4a1d-877e-d4c94775126f",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-09.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a4602-209c-49df-bfc9-997369fbf13c",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**과대 적합 모델의 학습 곡선 특징**\n",
    "\n",
    "아래 그래프는 2차 다항 함수의 분포를 따르는 데이터셋에 10차 다항회귀 모델을 적용한 학습 곡선을 보여준다.\n",
    "\n",
    "* 훈련셋(빨강)에 대한 성능: 훈련 데이터에 대한 평균 제곱근 오차가 매우 낮음.\n",
    "* 검증셋(파랑)에 대한 성능: 훈련 데이터에 대한 성능과 차이가 어느 정도 이상 벌어짐."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825cfc2c-f261-4c72-8c9b-69f71309630c",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-10.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b91447-6933-42c8-89ea-9ff62837ceb1",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**과대 적합 모델 개선법**\n",
    "\n",
    "과대 적합 모델을 개선하기 위해 일반적으로 학습 곡선에 사용된 두 그래프가 맞닿을 때까지 훈련 데이터를 추가한다.\n",
    "하지만 일반적으로 더 많은 훈련 데이터를 구하는 일이 매우 어렵거나 불가능할 수 있기 때문에 \n",
    "일반적으로 **모델 규제**를 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3c230-6173-4d24-a627-97cc33ec6a6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**모델의 일반화 성능**\n",
    "\n",
    "훈련 과정에서 다루지 않은 새로운 데이터 대한 예측 능력이 모델의 **일반화 성능**이다.\n",
    "새로운 데이터에 대한 모델의 예측에 나쁜 영향을 미치는 요소는 일반적으로 다음 세 가지가 있다.\n",
    "\n",
    "- 편향: 실제로는 2차원 모델인데 1차원 모델을 사용하는 경우처럼 데이터의 분포에 대한 잘못된 가정으로 인해 발생한다.\n",
    "    과소 적합이 발생할 가능성이 매우 높다.\n",
    "\n",
    "- 분산: 모델이 훈련 데이터에 민감하게 반응하는 정도를 가리킨다.\n",
    "    고차 다항 회귀 모델처럼 모델이 학습해야하는 파라미터의 수가 많을 수록,\n",
    "    즉 모델의 **자유도**<font size='2'>degree of freedom</font>가 높을 수록 분산이 커진다.\n",
    "- 제거 불가능 오류: 잡음(noise) 등 데이터 자체의 한계로 인해 발생한다.\n",
    "    데이터 전처리 과정에서 잡음 등을 제거해야만 오류를 줄일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4f08a-2cbe-462f-9acf-278fb04e66c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**편향-분산 트레이드오프**\n",
    "\n",
    "복잡한 모델일 수록 편향을 줄어들지만 분산은 커지는 현상을 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c8a26-03fd-4ccc-aba6-92255ef0be51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 모델 규제와 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece7fb2-0fca-4239-8585-07433ea01b48",
   "metadata": {},
   "source": [
    "훈련 중에 과소 적합이 발생하면 보다 복잡한 모델을 선택해야 한다.\n",
    "반면에 과대 적합이 발생할 경우 보다 단순한 모델을 사용하거나 모델에 규제를 가해서\n",
    "모델의 분산을 줄여 과대 적합을 방지하거나 과대 적합이 최대한 늦게 발생하도록 유도해야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc82208e-621d-4cc4-b50d-31c1f9601f9d",
   "metadata": {},
   "source": [
    "### 모델 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba0130a-4670-4582-a14d-79c5ffe09b16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "회귀 모델에 대한 **규제**<font size='2'>regularization</font>는 가중치의 역할을 제한하는 방식으로 이루어지며,\n",
    "방식에 따라 다음 세 가지 회귀 모델이 지정된다.\n",
    "\n",
    "* 릿지 회귀\n",
    "* 라쏘 회귀\n",
    "* 엘라스틱 넷"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e77e8-292a-4cf2-be4a-f881e208d234",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**릿지 회귀<font size='2'>Ridge Regression</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f46ed4-ce84-420c-95e2-e4b63cba042b",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "아래 비용 함수를 사용한다.\n",
    "\n",
    "$$J(\\theta) = \\textrm{MSE}(\\theta) + \\frac{\\alpha}{m} \\sum_{i=1}^{n}\\theta_i^2$$\n",
    "\n",
    "* $\\theta_0$: 규제에서 제외.\n",
    "* $m$: 배치 크기\n",
    "* $\\alpha$(알파): 규제 강도. \n",
    "    - $\\alpha=0$일 때 규제 없음.\n",
    "    - $\\alpha$ 가 커질 수록 가중치의 역할이 줄어듦.\n",
    "        비용을 줄이기 위해 가중치를 작게 유지하도록 훈련되어 결국 모델의 분산 정도가 작아짐."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b453ac-f270-43d5-8dee-6d9a0c2e6642",
   "metadata": {},
   "source": [
    "`StandardScaler` 등을 사용하여 특성 스케일링을 진행 한 다음에\n",
    "규제를 적용해야 모델의 성능이 좋아진다.\n",
    "이유는 $\\theta_i$ 값이 특성의 크기에 의존하기에\n",
    "모든 특성의 크기를 비슷하게 맞추면 $\\theta_i$가 \n",
    "보다 일정하게 수렴하기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb267e-02ce-4249-9407-bf93425062ba",
   "metadata": {},
   "source": [
    "아래 그림은 서로 다른 규제 강도를 사용한 릿지 회귀 모델의 훈련 결과를 보여준다.\n",
    "\n",
    "- 왼편: 선형 회귀 모델에 세 개의 $\\alpha$ 값 적용.\n",
    "- 오른편: 10차 다항 회귀 모델에 세 개의 $\\alpha$ 값 적용."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcfa518-9174-4d21-982b-2cb00665d83d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/ridge01.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f065b2-d730-446b-88c5-d11995d0b8ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**라쏘 회귀<font size='2'>Lasso Regression</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd091c7-d0af-432d-bcbc-e54376a105d3",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "아래 비용 함수를 사용한다.\n",
    "\n",
    "$$J(\\theta) = \\textrm{MSE}(\\theta) + 2\\alpha \\, \\sum_{i=1}^{n}\\mid \\theta_i\\mid$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec1d56-e794-4d6f-af78-3f574c307a7a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "별로 중요하지 않은 특성에 대해 $\\theta_i$가 \n",
    "빠르게 0에 수렴하도록 훈련 중에 유도된다.\n",
    "이유는 $\\mid \\theta_i \\mid$ 의 미분값이 1 또는 -1 이라는 상대적으로 큰 값이기에\n",
    "파라미터 업데이트 과정에서 보다 작은 $\\mid \\theta_i \\mid$가 보다 빠르게 0에 수렴하기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c64e3-c042-4066-9cc6-f6fdfcb593bc",
   "metadata": {},
   "source": [
    "아래 그림은 서로 다른 규제 강도를 사용한 라쏘 회귀 모델의 훈련 결과를 보여준다.\n",
    "\n",
    "- 왼편: 선형 회귀 모델에 세 개의 $\\alpha$ 값 적용.\n",
    "- 오른편: 10차 다항 회귀 모델에 세 개의 $\\alpha$ 값 적용."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c22e4a-a53f-4279-8898-138d255630a4",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/lasso01.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60fdee0-54f9-461e-af32-3750de7ff0e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**엘라스틱 넷<font size='2'>Elastic Net</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1d09c-a348-40fe-892c-c4348b553540",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "릿지 회귀와 라쏘 회귀를 절충한 아래 비용 함수를 사용한다.\n",
    "\n",
    "$$\n",
    "J(\\theta) = \n",
    "\\textrm{MSE}(\\theta) + \n",
    "r\\cdot \\bigg (2 \\alpha \\, \\sum_{i=1}^{n}\\mid\\theta_i\\mid \\bigg) + \n",
    "(1-r)\\cdot \\bigg (\\frac{\\alpha}{m}\\, \\sum_{i=1}^{n}\\theta_i^2 \\bigg )\n",
    "$$\n",
    "\n",
    "- $r$: 릿지 회귀에 사용되는 규제와 라쏘 회귀에 사용되는 규제의 사용 비율\n",
    "- 규제 강도를 의미하는 $\\alpha$가 각 규제에 가해지는 정도가 다름에 주의할 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aedfe3-45e0-4742-8f73-e4c2539eb2a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**규제 선택**\n",
    "\n",
    "약간이라도 규제를 사용해야 하며, 일반적으로 릿지 회귀가 추천된다.\n",
    "반면에 유용하지 않은 속성이 많다고 판단되는 경우엔 라쏘 회귀 또는 엘라스틱 넷이 추천된다.\n",
    "하지만 특성 수가 훈련 샘플 수보다 많거나 특성 몇 개가 상호 강하게 연관되어 있는 경우엔 엘라스틱 넷을 추천한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e4ce24-e9f0-4ba3-9a92-634828ef316f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(sec:early-stopping)=\n",
    "### 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ff52b-b9e6-4948-bc95-1b214ed763bd",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**조기 종료**<font size='2'>early stopping</font>는 \n",
    "모델이 훈련셋에 과대 적합하는 것을 방지하기 위해 훈련을 적절한 시기에 중단시키는 기법이며,\n",
    "가장 많이 사용된다.\n",
    "조기 종료는 검증셋에 대한 비용 함수의 값, 즉 검증셋에 대한 손실값이 더 이상 제대로 줄어들지 않으면 바로 훈련을 종료한다.\n",
    "\n",
    "아래 그래프는 2차 함수 곡선 형식으로 분포된 데이터셋에 90차 다항 회귀 모델을 훈련시킨 결과를 보여준다.\n",
    "실행된 에포크가 많아질 수록 훈련셋에 대한 모델의 비용(RMSE)이 점차 낮아지는 반면에\n",
    "검증셋에 대한 비용은 250 에포크 정도 지나면서 늘기 시작한다. \n",
    "즉, 모델이 훈련셋에 과하게 적응하기 시작했고, 이는 모델의 일반화 성능이 떨어지기 시작함을 의미한다.\n",
    "따라서 허용된 최대 500 에포크를 훈련하지 않고 250 에포크 정도에서 훈련을 멈추도록 하는 게\n",
    "조기 종료다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35282eef-f5ff-40ac-b518-364ecc86cbc8",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-11.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3188d-d056-4858-818a-a300447bf81a",
   "metadata": {},
   "source": [
    "확률적 경사하강법, 미니 배치 경사하강법에서는 비용 함수의 값, 즉 손실값이 보다 많이 진동하기에\n",
    "비용이 언제 최소가 되었는지 알기 어렵다.\n",
    "따라서 한동안, 보통 5 에포크 정도, 그동안의 훈련동안 기록된 최소의 손실값보다 새로 계산된 손실값이 높게 유지될 때 \n",
    "훈련을 멈추고 그동한 기록된 최소의 손실값 계산에 사용된 최적의 파라미터를 사용하는 모델로 되돌린다.\n",
    "\n",
    "사이킷런의 `SGDRegressor` 모델은 위에서 언급한 `early_stopping` 하이퍼파라미터의 값을 `True`로 지정하면\n",
    "훈련셋의 일부를 검증셋으로 진행한 다음에 조기 종료 기능을 갖춘 상태로 훈련을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1127cf-cef9-4027-b27b-ed9adba5087f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e059438-31f2-4a4f-966b-fdff4fc978a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "로지스틱 회귀는 회귀 모델의 결과를 분류 모델로 활용할 수 있도록 해주며\n",
    "분류 모델에서 가장 중요한 역할을 수행한다.\n",
    "로지스틱 회귀는 이진 분류에 사용되며, 다중 클래스 분류에는 로지스틱 회귀을 일반화한 소프트맥스 회귀가 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735d6a1-3430-49d6-8420-b93aef79251f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 시그모이드 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a084e-44a7-4944-aea6-e6d3c9707553",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "시그모이드 함수는 다음과 같이 정의된다.\n",
    "\n",
    "$$\\sigma(t) = \\frac{1}{1 + e^{-t}}$$\n",
    "\n",
    "그래프로 그리면 $t=0$일 때 0.5를 가지면 그보다 크면 1에, 작으면 -1에 수렴한다.\n",
    "\n",
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-12.png\" width=\"500\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a213f90-e23b-4280-8b91-938c87d0c9e5",
   "metadata": {},
   "source": [
    "**확률 예측**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae4649-c23e-4546-820e-90f3ae7607ed",
   "metadata": {},
   "source": [
    "로지스티 회귀 모델은 먼저 선형 회귀 모델이 예측한 값에 **시그모이드**<font size='2'>sigmoid</font> 함수를\n",
    "적용하여 0과 1 사이의 값, 즉 양성일 **확률** $\\hat p$ 로 지정한다.\n",
    "\n",
    "$$\n",
    "\\hat p = h_\\theta(\\mathbf{x}) \n",
    "= \\sigma(\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6993bae-0285-4566-9906-4bbea25e243f",
   "metadata": {},
   "source": [
    "**로지스틱 회귀 모델의 예측값**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec43b6-5297-4ec3-860b-47deff9d82e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "로지스틱 회귀 모델의 예측값은 계산된 확률이 0.5 이상인지 여부로 결정한다.\n",
    "\n",
    "$$\n",
    "\\hat y = \n",
    "\\begin{cases}\n",
    "0 & \\text{if}\\,\\, \\hat p < 0.5 \\\\[1ex]\n",
    "1 & \\text{if}\\,\\, \\hat p \\ge 0.5\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86fd66-98a8-4ae0-87a0-f0900f7dd403",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "이는 다음과 같이 가중치와 특성의 선형 조합 결과가 0 이상인지 여부에 따라 양성 또는 음성으로 판별함을 의미한다.\n",
    "\n",
    "* 양성: $\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n \\ge 0$ 인 경우\n",
    "* 음성: $\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n < 0$ 인 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7347e8e-c48b-4b51-b69b-c8951a79a5ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로그 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e1a314-b6ee-46bf-a9ef-7992c703ba55",
   "metadata": {},
   "source": [
    "로지스틱 회귀 모델은 \n",
    "아래 **로그 손실**<font size='2'>log loss</font> 함수를 비용 함수로 사용한다.\n",
    "\n",
    "$$\n",
    "J(\\theta) = \n",
    "- \\frac{1}{m}\\, \\sum_{i=1}^{m}\\, \\left( y^{(i)} \\cdot \\log(\\,\\hat p^{(i)}\\,) + (1-y^{(i)}) \\cdot \\log(\\,1 - \\hat p^{(i)}\\,)\\right)\n",
    "$$\n",
    "\n",
    "그러면 양성 샘플에 대해서는 1에 가까운 확률값을,\n",
    "음성 샘플에 대해서는 0에 가까운 확률값을 내도록 훈련한다.\n",
    "실제로 양성 샘플에 대해 0에 가까운 값을 예측하거나,\n",
    "음성 샘플에 대해 1에 가까운 값을 예측하면 \n",
    "비용 함수의 값이 매우 커지게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c298c-bc7f-4c44-8d94-836f91cca3cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**로그 손실 함수 이해**\n",
    "\n",
    "틀린 예측을 하면 로그 손실값이 매우 커진다. 이유는 아래 식에서 바로 찾을 수 있다.\n",
    "\n",
    "$$\n",
    "-\\left(y^{(i)} \\cdot \\log(\\,\\hat p^{(i)}\\,) + (1-y^{(i)}) \\cdot \\log(\\,1 - \\hat p^{(i)}\\right)\n",
    "$$\n",
    "\n",
    "- 첫째, 샘플의 레이블 $y^{(i)}$가 1(양성)이지만 예측 확률($\\hat p^{(i)}$)가 0에 가까워 음성으로 예측되는 경우엔 \n",
    "손실값 $-\\log(\\,\\hat p^{(i)}\\,)$가 매우 커질 수 있음(아래 왼쪽 그림 참고).\n",
    "- 둘째, 샘플의 레이블 $y^{(i)}$가 0(음성)이지만 예측 확률($\\hat p^{(i)}$)가 1에 가까워 양성으로 예측되는 경우엔 \n",
    "손실값 $-\\log(\\,\\hat p^{(i)}\\,)$가 매우 커질 수 있음(아래 오른쪽 그림 참고)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f63ae8-4cdb-4aef-a4f2-17160169b360",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-12-10a.png\" width=\"500\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c0c93d-e2bd-4b31-9c99-e67f0e1c0868",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ":::{admonition} 로그 손실 함수와 최적의 모델\n",
    ":class: note\n",
    "\n",
    "훈련셋이 가우스 분포를 따른다는 전제하에 로그 손실 함수를 최소화하면 \n",
    "최적의 모델을 얻을 수 있다는 사실이\n",
    "수학적으로 증명되었다.\n",
    "상세 내용은 [앤드류 응(Andrew Ng) 교수의 Stanford CS229](https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) 강의에서 확인할 수 있다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39986f12-0dcb-4c55-adfd-eaa6aed7971b",
   "metadata": {},
   "source": [
    "### 이진 분류 예제: 붓꽃 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03797c9-c984-429b-ad5b-24e0769c3e45",
   "metadata": {},
   "source": [
    "붓꽃의 품종 분류를 로지스틱 회귀로 진행한다.\n",
    "붓꽃 데이터셋의 샘플은 꽃받침<font size='2'>sepal</font>의 길이와 너비, \n",
    "꽃입<font size='2'>petal</font>의 길이와 너비 등 총 4개의 특성으로 \n",
    "이루어진다. \n",
    "\n",
    "```python\n",
    "[꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6721e6-0a86-4b73-a38a-a1612f1daa85",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/datapy/master/jupyter-book//images/iris_petal-sepal.png\" width=\"500\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28e434-93fc-461d-9381-ddde49cec254",
   "metadata": {},
   "source": [
    "레이블은 0, 1, 2 중에 하나이며 각 숫자는 하나의 품종을 가리킨다. \n",
    "\n",
    "* 0: Iris-Setosa(세토사)\n",
    "* 1: Iris-Versicolor(버시컬러)\n",
    "* 2: Iris-Virginica(버지니카)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e999b-6da8-4ede-87af-53dc70f43be8",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/iris01.png\" width=\"600\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03269642-9171-4682-a5e3-6d14e52f4b02",
   "metadata": {},
   "source": [
    "**붓꽃 데이터셋 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d0c8f-6caf-4f07-aae8-0a5a02092794",
   "metadata": {},
   "source": [
    "붓꽃 데이터셋은 머신러닝 분류 모델을 소개할 때 자주 활용되는 유명한 데이터셋이다.\n",
    "많은 서이트에서 다운로드 서비스를 제공하지만 여기서는 사이킷런 자체로 제공하는 데이터셋을 불러온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa93ccd-9565-4e29-9f2d-f973e7baae8e",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9bf41-b9ce-4eb0-b97d-d0865c5cd9f0",
   "metadata": {},
   "source": [
    "`load_iris()` 함수는 데이터셋을 사전 자료형과 유사한 `Bunch` 자료형으로 불러온다.\n",
    "사용되는 키(key) 중에 `data` 키와 연결된 값이 4개의 특성으로 구성된 훈련셋 데이터프레임<font size='2'>DataFrame</font>이고\n",
    "`target` 키와 연결된 값이 레이블셋 시리즈<font size='2'>Series</font>이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b5307-b0a0-4f41-b17a-56ea3ba4fed4",
   "metadata": {},
   "source": [
    "훈련셋의 처음 5개의 샘플은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f4483-7b69-46b0-9325-31a66a7282c5",
   "metadata": {},
   "source": [
    "```python\n",
    "    sepal length (cm) sepal width (cm) petal length (cm) petal width (cm)\n",
    "0    5.1               3.5              1.4               0.2\n",
    "1    4.9               3.0              1.4               0.2\n",
    "2    4.7               3.2              1.3               0.2\n",
    "3    4.6               3.1              1.5               0.2\n",
    "4    5.0               3.6              1.4               0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab753e-152c-4842-bedb-7919f9bbbe24",
   "metadata": {},
   "source": [
    "품종의 실제 이름은 `target_names` 키의 값으로 지정되었으며 다음과 같이\n",
    "`setosa`, `versicolor`, `virginica` 세 개의 품종이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba608295-f26d-49bb-8c70-e6dd81f204ad",
   "metadata": {},
   "source": [
    "```python\n",
    "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95432399-dab0-4fbc-8a12-d8a23280b62f",
   "metadata": {},
   "source": [
    "### 결정 경계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f992341-f6d4-4b35-b81c-82e993425f45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**버지니카 품종 감지기: 꽃잎 너비 특성 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c577d2-9a0e-44a1-8771-720e4043eede",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "로지스틱 회귀 모델을 이용하여 붓꽃의 품종이 버지니카인지 여부를 판별하는\n",
    "이진 분류기를 훈련시켜 보자.\n",
    "문제를 단순화하기 위해 꽃잎의 너비 특성 하나만 이용하여 붓꽃의 품종을 판별한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606e9bf-f95b-4284-8022-6bbc4bb3972a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "X = iris.data[[\"petal width (cm)\"]].values\n",
    "y = iris.target_names[iris.target] == 'virginica'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87142f62-370e-4c8d-acd9-be577241aea9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "훈련 결과 꽃잎의 너비가 1.65cm 보다 크면 버지니카 품종일 가능성이 50% 이상으로 계산된다.\n",
    "즉, 버지니카 품좀 감지기의 \n",
    "**결정 경계**<font size='2'>decision boundary</font>는 꽃잎 너비 기준으로 1.65cm 이다.\n",
    "\n",
    "아래 그림의 초록 실선은 꽃잎 너비 1.65 기준으로 버지니카 품종일 확율이 50%를 넘어서는 것을 보여준다.\n",
    "반면에 파랑 파선은 반대로 꽃잎 너비 1.65 기준으로 버니니카 품종이 아닐 확률이 50% 아래로 떨어지는 것을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f46a8-fe04-4c26-a885-92f341fc4a83",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/iris02.png\" width=\"700\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba714317-b525-48e8-bdba-eebf03f7eb23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**버지니카 품종 감지기: 꽃잎 길이와 너비 특성 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499638e-b4bf-4c4e-916c-7fb52a95a771",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "이번에는 꽃잎의 길이와 너비 두 특성을 이용하여 붓꽃의 품종을 판별하는 로지스틱 회귀 모델을 훈련한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904626c-fa4c-4493-aa1b-cbe408b2b7ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = iris.target_names[iris.target] == 'virginica'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(C=2, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09886cd3-f892-4f8f-9b2c-e8a1552a185e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**로지스틱 회귀 모델 규제**\n",
    "\n",
    "`LogisticRegression` 모델의 하이퍼파라미터 `penalty` 와 `C` 를 이용하여 규제와 규제의 강도를 지정한다. \n",
    "\n",
    "* `penalty`: `l1` 벌점 (라쏘 회귀), `l2` 벌점(릿지 회귀), `elasticnet`(엘라스틱 넷) 방식 중 하나 선택하며,\n",
    "    기본값은 `l2` 벌점이다. 즉, 릿지 회귀를 기본 회귀 모델로 사용한다.\n",
    "\n",
    "* `C`: `solver`로 지정되는 알고리즘에 따라 릿지 회귀 또는 라쏘 회귀 모델에 사용되는 $\\alpha$ 값의 역수에 해당한다. \n",
    "    따라서 0에 가까울 수록 강한 규제를 의미한다. \n",
    "    기본값은 1이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03aef91-2c36-456a-b581-b2d3a1371d30",
   "metadata": {},
   "source": [
    "아래 그림의 검정 파선은 꽃잎의 너비와 길이 두 속성을 이용했을 때 버지니카 품종의 여부를 \n",
    "결정하는 **결정 경계**를 나타낸다. \n",
    "반면에 다양한 색상의 직선은 버지니카 품종일 가능성(확률)을 보여주는 영역을 구분한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c4a59-3a0a-4b48-91ce-81f572a89a1f",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-15.png\" width=\"700\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40f4b9-52ec-4d66-a8e7-bb8dc57de540",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(sec:softmax-regression)=\n",
    "## 소프트맥스 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e2ea5-6291-46ad-81d9-7bb8e074f7c7",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "로지스틱 회귀 모델을 일반화하여 다중 클래스 분류를 지원하도록 만든 모델이\n",
    "**소프트맥스 회귀**<font size='2'>Softmax regression</font>다.\n",
    "즉, 소프트맥스 회귀는 3보다 같거나 큰 $K$개의 범주로 분류하는 모델이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f248f0-e250-4390-81cf-f60b7144cd64",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**소프트맥스 점수**\n",
    "\n",
    "입력 샘플 $\\mathbf x = [x_1, \\dots, x_n]$가 주어졌을 때 각각의 분류 클래스 $k \\in \\{1, 2, \\dots, K\\}$ 에 대해 **소프트맥스 점수** $s_k(\\mathbf x)$를\n",
    "선형 회귀 방식으로 계산한다.\n",
    "\n",
    "$$\n",
    "s_k(\\mathbf{x}) = \\theta_0^{(k)} + \\theta_1^{(k)} x_1 + \\cdots + \\theta_n^{(k)} x_n\n",
    "$$    \n",
    "\n",
    "$\\theta_i^{(k)}$ 는 샘플 $\\mathbf{x}$가 $k$-번째 클래스에 속할 가능성을 점수로 환산할 때 필요한\n",
    "$i$ 번째 특성에 대한 가중치 파라미터를 가리킨다.\n",
    "\n",
    "따라서 $K$ 개의 클래스로 분류하는 소프트맥스 회귀는\n",
    "총 $K \\cdot (n+1)$ 개의 파라미터를 학습한다.\n",
    "참고로 로지스틱 회귀는 $n+1$개의 파라미터만 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58005e24-b9dc-4202-9b8b-9bd08e5ee7ee",
   "metadata": {},
   "source": [
    "**소프트맥스 함수**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca41dbe-9bb4-46a7-88a9-24907943a4d8",
   "metadata": {},
   "source": [
    "입력 샘플 $\\mathbf x = [x_1, \\dots, x_n]$이 $k$-번째 범주에 속할 확률 $\\hat p_k$는 다음과 같이 계산된다.\n",
    "\n",
    "$$\n",
    "\\hat p_k \n",
    "= \\frac{\\exp(s_k(\\mathbf x))}{\\sum\\limits_{j=1}^{K}\\exp(s_j(\\mathbf x))}\n",
    "$$\n",
    "\n",
    "그러면 다음이 성립한다.\n",
    "\n",
    "$$\n",
    "\\sigma([s_1(\\mathbf{x}), \\cdots, \\cdots, s_k(\\mathbf{x})]) = [\\hat p_1, \\hat p_1, \\dots, \\hat p_{K}]\n",
    "$$\n",
    "\n",
    "위 식에서 $\\sigma()$는 아래와 같이 정의된 **소프트맥스 함수**를 가리킨다.\n",
    "\n",
    "$$\n",
    "\\sigma([v_1, \\cdots, v_K]) = [w_1, \\cdots, w_K], \\quad \\text{단 }w_k = \\frac{\\exp(v_k))}{\\sum\\limits_{k=1}^{K}\\exp(v_k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea79956-04c1-4aec-838e-cff5d6398d5e",
   "metadata": {},
   "source": [
    "**소프트맥스 회귀 모델의 예측 레이블**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de548a8-3cbe-4cef-a27b-370acf82450d",
   "metadata": {},
   "source": [
    "소프트맥스 회귀 모델의 각 샘플에 대한 최종 예측 레이블 $\\hat y$는\n",
    "확률값 $p_k$가 최댓값이 되는 $k$로 지정된다.\n",
    "즉, 다음이 성립해야 한다.\n",
    "\n",
    "$$\n",
    "\\hat y = p_k  \\quad\\Longleftrightarrow\\quad \\hat p_k = \\max([\\hat p_1, \\hat p_1, \\dots, \\hat p_{K}])\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27f3e3-a66b-49b0-8fe8-486718496cca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**소프트맥스 회귀의 비용 함수**\n",
    "\n",
    "각 분류 클래스 $k$에 대한 적절한 가중치들의 벡터 $\\mathbf{\\theta}^{(k)} = [\\theta_0^{(k)}, \\theta_1^{(k)}, \\dots, \\theta_n^{(k)}]$를 \n",
    "경사하강법을 이용하여 업데이트 한다.\n",
    "이를 위해 **크로스 엔트로피**<font size='2'>cross entropy</font>를 비용 함수로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e42e6f-8bf0-43af-9acb-93cafdc6462a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "J(\\Theta) = \n",
    "- \\frac{1}{m}\\, \\sum_{i=1}^{m}\\sum_{k=1}^{K} y^{(i)}_k\\, \\log\\big( \\hat{p}_k^{(i)}\\big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3f9d6-0f7c-41aa-a99a-e94929845085",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "위 식에 사용된 기호의 의미는 다음과 같다.\n",
    "\n",
    "| 기호 | 의미 |\n",
    "| :---: | :--- |\n",
    "| $y^{(i)}_k$ | $i$-번째 입력 샘플이 $k$-번째 범주에 포함되면 1, 아니면 0. |\n",
    "| $\\hat{p}_k^{(i)}$ | $i$-번째 입력 샘플이 $k$-번째 범주에 속할 확률 예측값 |\n",
    "| $\\Theta$ | $\\mathbf{\\theta}^{(k)}$로 구성된 파라미터 행렬. 정확한 모양은 여기서는 다루지 않음. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a4a170-7b9f-414d-a192-00b6f04f2ebf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$K=2$이면 다음이 성립한다.\n",
    "\n",
    "$$\n",
    "y^{(i)}_2 = 1-y^{(i)}_1, \\qquad \\hat{p}_2^{(i)} = 1- \\hat{p}_1^{(i)}\n",
    "$$\n",
    "\n",
    "이유는 1-번째 범주에 포함되지 않으면 반드시 2-번째 포함됨을 의미하고,\n",
    "따라서 2-번째 범주에 포함될 확률이 바로 1에서 1-번째 범주에 들어갈 확률을 뺀 값이기 때문이다.\n",
    "\n",
    "결국 크로스 엔트로피 비용함수는 $K=2$일 때, 이진 분류 모델인 로지스틱 회귀의 로그 손실 함수와 정확하게 일치한다.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "J(\\Theta) \n",
    "& = - \\frac{1}{m}\\, \\sum_{i=1}^{m} \\left(y^{(i)}_1\\, \\log( \\hat{p}_1^{(i)}) + (y^{(i)}_2\\, \\log( \\hat{p}_2^{(i)}) \\right) \\\\\n",
    "& = - \\frac{1}{m}\\, \\sum_{i=1}^{m} \\left(y^{(i)}_1\\, \\log( \\hat{p}_1^{(i)}) + (1-y^{(i)}_1)\\, \\log(1- \\hat{p}_1^{(i)}) \\right)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc61c7e-0b93-4d47-89f3-5055e834c226",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ":::{admonition} 크로스 엔트로피\n",
    ":class: note\n",
    "\n",
    "크로스 엔트로피는 주어진 샘플의 타깃 클래스를 제대로 예측하지 못하는 경우 높은 값을 갖는다.\n",
    "크로스 엔트로피 개념은 정보 이론에서 유래하며, \n",
    "자세한 설명은 오렐리앙 제롱의 동영상\n",
    "[\"A Short Introduction to Entropy, Cross-Entropy and KL-Divergence\"](https://www.youtube.com/watch?v=ErfnhcEV1O8)를\n",
    "참고한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf5e64-be2c-4e36-8376-dd4a186e00a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**붓꽃 데이터 다중 클래스 분류**\n",
    "\n",
    "사이킷런의 `LogisticRegression` 예측기를 활용한다.\n",
    "기본값 `solver=lbfgs` 사용하면 모델이 알아서 다중 클래스 분류를 훈련한다.\n",
    "아래 코드는 꽃잎의 길이와 너비 두 특성을 이용하여 \n",
    "세토사, 버시컬러, 버지니카 클래스 중 하나를 선택하는 모델을 훈련한다.\n",
    "\n",
    "```python\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = iris[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "softmax_reg = LogisticRegression(C=30, random_state=42) # 조금 약한 alpha 규제\n",
    "softmax_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39e117-1b99-49b9-a4f3-a9e1c902c042",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "아래 그림은 붓꽃 꽃잎의 너비와 길이를 기준으로 세 개의 품종을 색까로 구분하는 결정 경계를 보여준다. \n",
    "다양한 색상의 곡선은 버시컬러 품종에 속할 확률의 영역 구분하는 등고선이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76243c65-580f-4052-925f-ec15d2c4294a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-16.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea219563-dca6-435f-b63c-347a7d77c17d",
   "metadata": {},
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31796ab3-7369-4734-99e2-498f9685e2e9",
   "metadata": {},
   "source": [
    "참고: [(실습) 모델 훈련](https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/practices/practice_training_models.ipynb) 와\n",
    "[(실습) 머신러닝 모델 웹앱](https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/practices/practice_webApp_mlModel.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}